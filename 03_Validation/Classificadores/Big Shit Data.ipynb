{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcosfabricio/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer,StandardScaler,MaxAbsScaler, LabelEncoder\n",
    "\n",
    "#import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando a coluna de sexo de testo pra numero e considerando ela como dado categorico\n",
    "df = pd.read_csv(\"abalone_dataset.csv\")\n",
    "df['sex'] = LabelEncoder().fit_transform(df['sex'].tolist())\n",
    "df['sex'] = df['sex'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento da base\n",
    "preps = [MinMaxScaler,Normalizer,StandardScaler,MaxAbsScaler]\n",
    "# Modelos a serem testados\n",
    "models = [SVC,LogisticRegression,MLPClassifier,RandomForestClassifier,DecisionTreeClassifier]\n",
    "# Pipeline para testar todos os modelos com todos os preprocessamento\n",
    "pipes = [make_pipeline(prepo(),model()) for model in models for prepo in preps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for pipe in pipes:\n",
    "    res = np.median(cross_validate(pipe,df.drop(columns=\"type\"),df[\"type\"],scoring=\"accuracy\",cv=10)[\"test_score\"])\n",
    "    results.append(np.append(np.array(pipe.steps)[:,0],res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Model</th>\n",
       "      <th>Median-Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.654952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.654460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.653904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.651275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.645932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.642169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.638404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.636807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.626801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.620414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.618806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.616610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.615007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.613415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.609599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.571885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.569612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.563002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.558404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.558210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Preprocessing                   Model  Median-Accuracy\n",
       "6   standardscaler      logisticregression         0.654952\n",
       "10  standardscaler           mlpclassifier         0.654460\n",
       "2   standardscaler                     svc         0.653904\n",
       "11    maxabsscaler           mlpclassifier         0.651275\n",
       "8     minmaxscaler           mlpclassifier         0.645932\n",
       "9       normalizer           mlpclassifier         0.642169\n",
       "4     minmaxscaler      logisticregression         0.638404\n",
       "7     maxabsscaler      logisticregression         0.636807\n",
       "14  standardscaler  randomforestclassifier         0.626801\n",
       "5       normalizer      logisticregression         0.620414\n",
       "13      normalizer  randomforestclassifier         0.618806\n",
       "3     maxabsscaler                     svc         0.616610\n",
       "0     minmaxscaler                     svc         0.615007\n",
       "15    maxabsscaler  randomforestclassifier         0.613415\n",
       "12    minmaxscaler  randomforestclassifier         0.609599\n",
       "19    maxabsscaler  decisiontreeclassifier         0.571885\n",
       "17      normalizer  decisiontreeclassifier         0.569612\n",
       "1       normalizer                     svc         0.563002\n",
       "16    minmaxscaler  decisiontreeclassifier         0.558404\n",
       "18  standardscaler  decisiontreeclassifier         0.558210"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results,columns=[\"Preprocessing\",\"Model\",\"Median-Accuracy\"]).sort_values(by=\"Median-Accuracy\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegamos o melhor modelo e preprocessamento, para testar no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline para o grid search\n",
    "pipe = make_pipeline(StandardScaler(),LogisticRegression())\n",
    "# Dicionario de parametros a serem testados pelo grid search\n",
    "parameters = {'logisticregression__penalty':['l2'], 'logisticregression__solver':('newton-cg', 'lbfgs', 'sag', 'saga'), 'logisticregression__C': (np.arange(10,100,10)), 'logisticregression__multi_class':['multinomial'], 'logisticregression__max_iter':[1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch com cros validation, testa o modelo com todas as combinações de parametros passadas no dicionario,\n",
    "# e classifica a melhor de acordo com uma metrica que escolhermos, nesse caso a acuracia.\n",
    "clf = GridSearchCV(pipe,parameters,scoring=\"accuracy\", cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 92.9 ms, total: 1.44 s\n",
      "Wall time: 53.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'logisticregression__penalty': ['l2'], 'logisticregression__solver': ('newton-cg', 'lbfgs', 'sag', 'saga'), 'logisticregression__C': array([10, 20, 30, 40, 50, 60, 70, 80, 90]), 'logisticregression__multi_class': ['multinomial'], 'logisticregression__max_iter': [1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(df.drop(columns=\"type\"),df[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de atributos recursivamente\n",
    "- selecionamos a melhor combinação de hiperparametros do modelo com o grid search\n",
    "- aplicamos a seleção de atributos nesse modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = clf.best_estimator_.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seletor = RFECV(log, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=10,\n",
       "   estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "   n_jobs=1, scoring='accuracy', step=1, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seletor.fit(df.drop(columns=\"type\"),df[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['length', 'diameter', 'height', 'whole_weight', 'shucked_weight',\n",
       "       'viscera_weight', 'shell_weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Atributos selecionados\n",
    "df.drop(columns=\"type\").columns[seletor.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (accuracy)\")\n",
    "plt.plot(range(1, len(seletor.grid_scores_) + 1), seletor.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando vetor resposta pra enviar ao servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.read_csv(\"abalone_app.csv\")\n",
    "teste['sex'] = LabelEncoder().fit_transform(teste['sex'].tolist())\n",
    "teste['sex'] = teste['sex'].astype('category')\n",
    "base = teste[teste.columns[seletor.get_support()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.2290</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.4150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.1185</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.2445</td>\n",
       "      <td>0.2845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.3170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3715</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.5555</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.4440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.415</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.1545</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.235</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.2040</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>0.3225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.575</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.9215</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.1045</td>\n",
       "      <td>0.4565</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.695</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.6365</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>0.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.185</td>\n",
       "      <td>1.5280</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.3025</td>\n",
       "      <td>0.4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.505</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.3610</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.1155</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.3790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.745</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.9310</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.4585</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.605</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.3820</td>\n",
       "      <td>0.6090</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.555</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.2095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.570</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.635</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.3750</td>\n",
       "      <td>0.6230</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.3585</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.3745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.635</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.2615</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9740</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.4085</td>\n",
       "      <td>0.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.7510</td>\n",
       "      <td>0.8950</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.4700</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.4020</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.2935</td>\n",
       "      <td>0.3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.4385</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>0.2745</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.260</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.8045</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.6190</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.4650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.7825</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.4285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1.0485</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7995</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>0.515</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.6115</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3100</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.705</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.215</td>\n",
       "      <td>2.1410</td>\n",
       "      <td>1.0465</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0.665</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.2695</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.265</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.205</td>\n",
       "      <td>2.2635</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.4230</td>\n",
       "      <td>0.7260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0.510</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.3435</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0.615</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.1980</td>\n",
       "      <td>0.7070</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>0.2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.5075</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>0.430</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.0770</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.3095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "0      0.600     0.480   0.175        1.2290          0.4125          0.2735   \n",
       "1      0.545     0.385   0.150        1.1185          0.5425          0.2445   \n",
       "2      0.645     0.520   0.180        1.2850          0.5775          0.3520   \n",
       "3      0.640     0.510   0.170        1.3715          0.5670          0.3070   \n",
       "4      0.655     0.540   0.215        1.5555          0.6950          0.2960   \n",
       "5      0.415     0.300   0.100        0.3355          0.1545          0.0685   \n",
       "6      0.235     0.175   0.065        0.0615          0.0205          0.0200   \n",
       "7      0.655     0.490   0.160        1.2040          0.5455          0.2615   \n",
       "8      0.575     0.450   0.165        0.9215          0.3275          0.2250   \n",
       "9      0.550     0.425   0.155        0.9175          0.2775          0.2430   \n",
       "10     0.590     0.500   0.165        1.1045          0.4565          0.2425   \n",
       "11     0.695     0.550   0.160        1.6365          0.6940          0.3005   \n",
       "12     0.660     0.505   0.185        1.5280          0.6900          0.3025   \n",
       "13     0.490     0.385   0.140        0.5425          0.1980          0.1270   \n",
       "14     0.505     0.380   0.135        0.6855          0.3610          0.1565   \n",
       "15     0.610     0.475   0.160        1.1155          0.3835          0.2230   \n",
       "16     0.580     0.445   0.145        0.8880          0.4100          0.1815   \n",
       "17     0.300     0.230   0.095        0.1385          0.0560          0.0365   \n",
       "18     0.745     0.565   0.215        1.9310          0.8960          0.4585   \n",
       "19     0.605     0.475   0.175        1.3820          0.6090          0.2325   \n",
       "20     0.555     0.430   0.125        0.7005          0.3395          0.1355   \n",
       "21     0.545     0.440   0.120        0.8565          0.3475          0.1715   \n",
       "22     0.375     0.290   0.085        0.2385          0.1180          0.0450   \n",
       "23     0.570     0.470   0.140        0.8710          0.3850          0.2110   \n",
       "24     0.635     0.490   0.175        1.3750          0.6230          0.2705   \n",
       "25     0.550     0.445   0.125        0.6720          0.2880          0.1365   \n",
       "26     0.620     0.475   0.195        1.3585          0.5935          0.3365   \n",
       "27     0.635     0.490   0.170        1.2615          0.5385          0.2665   \n",
       "28     0.500     0.400   0.165        0.7105          0.2700          0.1455   \n",
       "29     0.740     0.600   0.195        1.9740          0.5980          0.4085   \n",
       "...      ...       ...     ...           ...             ...             ...   \n",
       "1015   0.700     0.565   0.180        1.7510          0.8950          0.3355   \n",
       "1016   0.710     0.555   0.170        1.4700          0.5375          0.3800   \n",
       "1017   0.655     0.525   0.180        1.4020          0.6240          0.2935   \n",
       "1018   0.450     0.340   0.105        0.4385          0.2100          0.0925   \n",
       "1019   0.525     0.420   0.160        0.7560          0.2745          0.1730   \n",
       "1020   0.260     0.200   0.065        0.0960          0.0440          0.0270   \n",
       "1021   0.535     0.400   0.150        0.8045          0.3345          0.2125   \n",
       "1022   0.670     0.540   0.195        1.6190          0.7400          0.3305   \n",
       "1023   0.680     0.540   0.195        1.7825          0.5565          0.3235   \n",
       "1024   0.550     0.435   0.160        0.9060          0.3420          0.2190   \n",
       "1025   0.610     0.425   0.155        1.0485          0.5070          0.1955   \n",
       "1026   0.525     0.425   0.145        0.7995          0.3345          0.2090   \n",
       "1027   0.470     0.385   0.130        0.5870          0.2640          0.1170   \n",
       "1028   0.435     0.330   0.125        0.4060          0.1685          0.1055   \n",
       "1029   0.515     0.385   0.125        0.6115          0.3175          0.1265   \n",
       "1030   0.700     0.575   0.170        1.3100          0.5095          0.3140   \n",
       "1031   0.705     0.555   0.215        2.1410          1.0465          0.3830   \n",
       "1032   0.665     0.515   0.200        1.2695          0.5115          0.2675   \n",
       "1033   0.265     0.195   0.060        0.0920          0.0345          0.0250   \n",
       "1034   0.750     0.615   0.205        2.2635          0.8210          0.4230   \n",
       "1035   0.510     0.380   0.135        0.6810          0.3435          0.1420   \n",
       "1036   0.615     0.450   0.150        1.1980          0.7070          0.2095   \n",
       "1037   0.645     0.525   0.160        1.5075          0.7455          0.2450   \n",
       "1038   0.380     0.270   0.095        0.2190          0.0835          0.0515   \n",
       "1039   0.455     0.375   0.125        0.5330          0.2330          0.1060   \n",
       "1040   0.430     0.350   0.105        0.3660          0.1705          0.0855   \n",
       "1041   0.475     0.360   0.125        0.4470          0.1695          0.0810   \n",
       "1042   0.500     0.405   0.150        0.5965          0.2530          0.1260   \n",
       "1043   0.380     0.275   0.095        0.2425          0.1060          0.0485   \n",
       "1044   0.590     0.475   0.165        1.0770          0.4545          0.2440   \n",
       "\n",
       "      shell_weight  \n",
       "0           0.4150  \n",
       "1           0.2845  \n",
       "2           0.3170  \n",
       "3           0.4090  \n",
       "4           0.4440  \n",
       "5           0.0950  \n",
       "6           0.0190  \n",
       "7           0.3225  \n",
       "8           0.2560  \n",
       "9           0.3350  \n",
       "10          0.3400  \n",
       "11          0.4400  \n",
       "12          0.4410  \n",
       "13          0.1750  \n",
       "14          0.1610  \n",
       "15          0.3790  \n",
       "16          0.2425  \n",
       "17          0.0370  \n",
       "18          0.5000  \n",
       "19          0.3985  \n",
       "20          0.2095  \n",
       "21          0.2400  \n",
       "22          0.0695  \n",
       "23          0.2315  \n",
       "24          0.3950  \n",
       "25          0.2100  \n",
       "26          0.3745  \n",
       "27          0.3800  \n",
       "28          0.2250  \n",
       "29          0.7100  \n",
       "...            ...  \n",
       "1015        0.4460  \n",
       "1016        0.4310  \n",
       "1017        0.3650  \n",
       "1018        0.1200  \n",
       "1019        0.2750  \n",
       "1020        0.0300  \n",
       "1021        0.2100  \n",
       "1022        0.4650  \n",
       "1023        0.4285  \n",
       "1024        0.2950  \n",
       "1025        0.2740  \n",
       "1026        0.2400  \n",
       "1027        0.1740  \n",
       "1028        0.0960  \n",
       "1029        0.1500  \n",
       "1030        0.4200  \n",
       "1031        0.5280  \n",
       "1032        0.4360  \n",
       "1033        0.0245  \n",
       "1034        0.7260  \n",
       "1035        0.1700  \n",
       "1036        0.2505  \n",
       "1037        0.4325  \n",
       "1038        0.0700  \n",
       "1039        0.1850  \n",
       "1040        0.1100  \n",
       "1041        0.1400  \n",
       "1042        0.1850  \n",
       "1043        0.2100  \n",
       "1044        0.3095  \n",
       "\n",
       "[1045 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(seletor.estimator_.predict(base)).to_csv(\"respostas.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
