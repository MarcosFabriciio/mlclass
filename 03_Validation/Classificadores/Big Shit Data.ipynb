{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcosfabricio/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer,StandardScaler,MaxAbsScaler, LabelEncoder\n",
    "\n",
    "#import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in listdir() if x.endswith(\".csv\")]\n",
    "files.remove('abalone_app.csv')\n",
    "files.remove('abalone_dataset.csv')\n",
    "files.remove('respostas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abalone_L2.csv',\n",
       " 'abalone_sex_bin.csv',\n",
       " 'abalone_L1.csv',\n",
       " 'abalone_min_max.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalones = []\n",
    "for file in files:\n",
    "    abalones.append(pd.read_csv(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preps = [MinMaxScaler,Normalizer,StandardScaler,MaxAbsScaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SVC,LogisticRegression,MLPClassifier,RandomForestClassifier,DecisionTreeClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipes = [make_pipeline(prepo(),model()) for model in models for prepo in preps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(),LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"abalone_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = LabelEncoder().fit_transform(df['sex'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'logisticregression__penalty':['l2'], 'logisticregression__solver':('newton-cg', 'lbfgs', 'sag', 'saga'), 'logisticregression__C': (np.arange(10,100,10)), 'logisticregression__multi_class':['multinomial'], 'logisticregression__max_iter':[1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipe,parameters,scoring=\"accuracy\", cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 138 ms, total: 1.65 s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'logisticregression__penalty': ['l2'], 'logisticregression__solver': ('newton-cg', 'lbfgs', 'sag', 'saga'), 'logisticregression__C': array([10, 20, 30, 40, 50, 60, 70, 80, 90]), 'logisticregression__multi_class': ['multinomial'], 'logisticregression__max_iter': [1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(df.drop(columns=\"type\"),df[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = clf.best_estimator_.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seletor = RFECV(log, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=10,\n",
       "   estimator=LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "   n_jobs=1, scoring='accuracy', step=1, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seletor.fit(df.drop(columns=\"type\"),df[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['length', 'diameter', 'height', 'whole_weight', 'shucked_weight',\n",
       "       'viscera_weight', 'shell_weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=\"type\").columns[seletor.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(seletor.grid_scores_) + 1), seletor.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.read_csv(\"abalone_app.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste['sex'] = LabelEncoder().fit_transform(teste['sex'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste['sex'] = teste['sex'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = teste[teste.columns[seletor.get_support()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.2290</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.4150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.1185</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.2445</td>\n",
       "      <td>0.2845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.3170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3715</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.5555</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.4440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.1545</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.2040</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>0.3225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.9215</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.1045</td>\n",
       "      <td>0.4565</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.6365</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>0.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.185</td>\n",
       "      <td>1.5280</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.3025</td>\n",
       "      <td>0.4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.3610</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.1155</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.3790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.9310</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.4585</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.3820</td>\n",
       "      <td>0.6090</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.2095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.3750</td>\n",
       "      <td>0.6230</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.3585</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.3745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.2615</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9740</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.4085</td>\n",
       "      <td>0.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>2</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.7510</td>\n",
       "      <td>0.8950</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.4700</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.4020</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.2935</td>\n",
       "      <td>0.3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.4385</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>0.2745</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.8045</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.6190</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.4650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>2</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.7825</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.4285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>2</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>1</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1.0485</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7995</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>1</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>1</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.6115</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3100</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>2</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.215</td>\n",
       "      <td>2.1410</td>\n",
       "      <td>1.0465</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>2</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.2695</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>1</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.205</td>\n",
       "      <td>2.2635</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.4230</td>\n",
       "      <td>0.7260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>2</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.3435</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>2</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.1980</td>\n",
       "      <td>0.7070</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>0.2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>2</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.5075</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>2</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>1</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>1</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>2</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.0770</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.3095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  length  diameter  height  whole_weight  shucked_weight  \\\n",
       "0      2   0.600     0.480   0.175        1.2290          0.4125   \n",
       "1      0   0.545     0.385   0.150        1.1185          0.5425   \n",
       "2      0   0.645     0.520   0.180        1.2850          0.5775   \n",
       "3      2   0.640     0.510   0.170        1.3715          0.5670   \n",
       "4      0   0.655     0.540   0.215        1.5555          0.6950   \n",
       "5      2   0.415     0.300   0.100        0.3355          0.1545   \n",
       "6      1   0.235     0.175   0.065        0.0615          0.0205   \n",
       "7      0   0.655     0.490   0.160        1.2040          0.5455   \n",
       "8      2   0.575     0.450   0.165        0.9215          0.3275   \n",
       "9      2   0.550     0.425   0.155        0.9175          0.2775   \n",
       "10     2   0.590     0.500   0.165        1.1045          0.4565   \n",
       "11     0   0.695     0.550   0.160        1.6365          0.6940   \n",
       "12     0   0.660     0.505   0.185        1.5280          0.6900   \n",
       "13     1   0.490     0.385   0.140        0.5425          0.1980   \n",
       "14     0   0.505     0.380   0.135        0.6855          0.3610   \n",
       "15     0   0.610     0.475   0.160        1.1155          0.3835   \n",
       "16     0   0.580     0.445   0.145        0.8880          0.4100   \n",
       "17     1   0.300     0.230   0.095        0.1385          0.0560   \n",
       "18     2   0.745     0.565   0.215        1.9310          0.8960   \n",
       "19     0   0.605     0.475   0.175        1.3820          0.6090   \n",
       "20     1   0.555     0.430   0.125        0.7005          0.3395   \n",
       "21     2   0.545     0.440   0.120        0.8565          0.3475   \n",
       "22     1   0.375     0.290   0.085        0.2385          0.1180   \n",
       "23     0   0.570     0.470   0.140        0.8710          0.3850   \n",
       "24     2   0.635     0.490   0.175        1.3750          0.6230   \n",
       "25     1   0.550     0.445   0.125        0.6720          0.2880   \n",
       "26     2   0.620     0.475   0.195        1.3585          0.5935   \n",
       "27     0   0.635     0.490   0.170        1.2615          0.5385   \n",
       "28     0   0.500     0.400   0.165        0.7105          0.2700   \n",
       "29     0   0.740     0.600   0.195        1.9740          0.5980   \n",
       "...   ..     ...       ...     ...           ...             ...   \n",
       "1015   2   0.700     0.565   0.180        1.7510          0.8950   \n",
       "1016   0   0.710     0.555   0.170        1.4700          0.5375   \n",
       "1017   2   0.655     0.525   0.180        1.4020          0.6240   \n",
       "1018   1   0.450     0.340   0.105        0.4385          0.2100   \n",
       "1019   0   0.525     0.420   0.160        0.7560          0.2745   \n",
       "1020   2   0.260     0.200   0.065        0.0960          0.0440   \n",
       "1021   0   0.535     0.400   0.150        0.8045          0.3345   \n",
       "1022   0   0.670     0.540   0.195        1.6190          0.7400   \n",
       "1023   2   0.680     0.540   0.195        1.7825          0.5565   \n",
       "1024   2   0.550     0.435   0.160        0.9060          0.3420   \n",
       "1025   1   0.610     0.425   0.155        1.0485          0.5070   \n",
       "1026   0   0.525     0.425   0.145        0.7995          0.3345   \n",
       "1027   1   0.470     0.385   0.130        0.5870          0.2640   \n",
       "1028   1   0.435     0.330   0.125        0.4060          0.1685   \n",
       "1029   1   0.515     0.385   0.125        0.6115          0.3175   \n",
       "1030   0   0.700     0.575   0.170        1.3100          0.5095   \n",
       "1031   2   0.705     0.555   0.215        2.1410          1.0465   \n",
       "1032   2   0.665     0.515   0.200        1.2695          0.5115   \n",
       "1033   1   0.265     0.195   0.060        0.0920          0.0345   \n",
       "1034   0   0.750     0.615   0.205        2.2635          0.8210   \n",
       "1035   2   0.510     0.380   0.135        0.6810          0.3435   \n",
       "1036   2   0.615     0.450   0.150        1.1980          0.7070   \n",
       "1037   2   0.645     0.525   0.160        1.5075          0.7455   \n",
       "1038   2   0.380     0.270   0.095        0.2190          0.0835   \n",
       "1039   1   0.455     0.375   0.125        0.5330          0.2330   \n",
       "1040   1   0.430     0.350   0.105        0.3660          0.1705   \n",
       "1041   0   0.475     0.360   0.125        0.4470          0.1695   \n",
       "1042   0   0.500     0.405   0.150        0.5965          0.2530   \n",
       "1043   1   0.380     0.275   0.095        0.2425          0.1060   \n",
       "1044   2   0.590     0.475   0.165        1.0770          0.4545   \n",
       "\n",
       "      viscera_weight  shell_weight  \n",
       "0             0.2735        0.4150  \n",
       "1             0.2445        0.2845  \n",
       "2             0.3520        0.3170  \n",
       "3             0.3070        0.4090  \n",
       "4             0.2960        0.4440  \n",
       "5             0.0685        0.0950  \n",
       "6             0.0200        0.0190  \n",
       "7             0.2615        0.3225  \n",
       "8             0.2250        0.2560  \n",
       "9             0.2430        0.3350  \n",
       "10            0.2425        0.3400  \n",
       "11            0.3005        0.4400  \n",
       "12            0.3025        0.4410  \n",
       "13            0.1270        0.1750  \n",
       "14            0.1565        0.1610  \n",
       "15            0.2230        0.3790  \n",
       "16            0.1815        0.2425  \n",
       "17            0.0365        0.0370  \n",
       "18            0.4585        0.5000  \n",
       "19            0.2325        0.3985  \n",
       "20            0.1355        0.2095  \n",
       "21            0.1715        0.2400  \n",
       "22            0.0450        0.0695  \n",
       "23            0.2110        0.2315  \n",
       "24            0.2705        0.3950  \n",
       "25            0.1365        0.2100  \n",
       "26            0.3365        0.3745  \n",
       "27            0.2665        0.3800  \n",
       "28            0.1455        0.2250  \n",
       "29            0.4085        0.7100  \n",
       "...              ...           ...  \n",
       "1015          0.3355        0.4460  \n",
       "1016          0.3800        0.4310  \n",
       "1017          0.2935        0.3650  \n",
       "1018          0.0925        0.1200  \n",
       "1019          0.1730        0.2750  \n",
       "1020          0.0270        0.0300  \n",
       "1021          0.2125        0.2100  \n",
       "1022          0.3305        0.4650  \n",
       "1023          0.3235        0.4285  \n",
       "1024          0.2190        0.2950  \n",
       "1025          0.1955        0.2740  \n",
       "1026          0.2090        0.2400  \n",
       "1027          0.1170        0.1740  \n",
       "1028          0.1055        0.0960  \n",
       "1029          0.1265        0.1500  \n",
       "1030          0.3140        0.4200  \n",
       "1031          0.3830        0.5280  \n",
       "1032          0.2675        0.4360  \n",
       "1033          0.0250        0.0245  \n",
       "1034          0.4230        0.7260  \n",
       "1035          0.1420        0.1700  \n",
       "1036          0.2095        0.2505  \n",
       "1037          0.2450        0.4325  \n",
       "1038          0.0515        0.0700  \n",
       "1039          0.1060        0.1850  \n",
       "1040          0.0855        0.1100  \n",
       "1041          0.0810        0.1400  \n",
       "1042          0.1260        0.1850  \n",
       "1043          0.0485        0.2100  \n",
       "1044          0.2440        0.3095  \n",
       "\n",
       "[1045 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(seletor.estimator_.predict(base)).to_csv(\"respostas.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for pipe in pipes:\n",
    "    res = np.median(cross_validate(pipe,df.drop(columns=\"type\"),df[\"type\"],scoring=\"accuracy\",cv=10)[\"test_score\"])\n",
    "    results.append(np.append(np.array(pipe.steps)[:,0],res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Model</th>\n",
       "      <th>Median-Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.654952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.654404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.653904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.653355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.643770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.638978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.638404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.636807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.630580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.620414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.618819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.617841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.616613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.616610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.615007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.567779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.563201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.563002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.561594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.556781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Preprocessing                   Model  Median-Accuracy\n",
       "6   standardscaler      logisticregression         0.654952\n",
       "9       normalizer           mlpclassifier         0.654404\n",
       "2   standardscaler                     svc         0.653904\n",
       "10  standardscaler           mlpclassifier         0.653355\n",
       "8     minmaxscaler           mlpclassifier         0.643770\n",
       "11    maxabsscaler           mlpclassifier         0.638978\n",
       "4     minmaxscaler      logisticregression         0.638404\n",
       "7     maxabsscaler      logisticregression         0.636807\n",
       "13      normalizer  randomforestclassifier         0.630580\n",
       "5       normalizer      logisticregression         0.620414\n",
       "14  standardscaler  randomforestclassifier         0.618819\n",
       "15    maxabsscaler  randomforestclassifier         0.617841\n",
       "12    minmaxscaler  randomforestclassifier         0.616613\n",
       "3     maxabsscaler                     svc         0.616610\n",
       "0     minmaxscaler                     svc         0.615007\n",
       "18  standardscaler  decisiontreeclassifier         0.567779\n",
       "16    minmaxscaler  decisiontreeclassifier         0.563201\n",
       "1       normalizer                     svc         0.563002\n",
       "19    maxabsscaler  decisiontreeclassifier         0.561594\n",
       "17      normalizer  decisiontreeclassifier         0.556781"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results,columns=[\"Preprocessing\",\"Model\",\"Median-Accuracy\"]).sort_values(by=\"Median-Accuracy\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Utilizado: abalone_L2.csv\n",
      "\n",
      "\tAcuracia: 0.6719745222929936\n",
      "\n",
      "Dataframe Utilizado: abalone_sex_bin.csv\n",
      "\n",
      "\tAcuracia: 0.6560509554140127\n",
      "\n",
      "Dataframe Utilizado: abalone_L1.csv\n",
      "\n",
      "\tAcuracia: 0.6719745222929936\n",
      "\n",
      "Dataframe Utilizado: abalone_min_max.csv\n",
      "\n",
      "\tAcuracia: 0.6560509554140127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,len(abalones)):\n",
    "    print(\"Dataframe Utilizado: {}\\n\".format(files[x]))\n",
    "    X,Y = abalones[x][abalones[x].columns[:-1]],abalones[x][abalones[x].columns[-1]]\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, stratify = Y, random_state=66, test_size=0.10)\n",
    "    tree = DecisionTreeClassifier(max_depth=5, random_state=0, max_leaf_nodes=15)\n",
    "    tree.fit(Xtrain,Ytrain)\n",
    "    print(\"\\tAcuracia: {}\\n\".format(tree.score(Xtest,Ytest)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
