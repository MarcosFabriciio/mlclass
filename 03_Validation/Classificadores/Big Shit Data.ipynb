{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer,StandardScaler,MaxAbsScaler, LabelEncoder\n",
    "\n",
    "#import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Transformando a coluna de sexo de testo pra numero e considerando ela como dado categorico\n",
    "df = pd.read_csv(\"abalone_dataset.csv\")\n",
    "# df['sex'] = LabelEncoder().fit_transform(df['sex'].tolist())\n",
    "# df['sex'] = df['sex'].astype('category')\n",
    "df = df.drop(columns = \"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento da base\n",
    "preps = [MinMaxScaler,Normalizer,StandardScaler,MaxAbsScaler]\n",
    "# Modelos a serem testados\n",
    "models = [SVC,LogisticRegression,MLPClassifier,RandomForestClassifier,DecisionTreeClassifier]\n",
    "# Pipeline para testar todos os modelos com todos os preprocessamento\n",
    "pipes = [make_pipeline(prepo(),model()) for model in models for prepo in preps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for pipe in pipes:\n",
    "#     res = np.median(cross_validate(pipe,df.drop(columns=\"type\"),df[\"type\"],scoring=\"accuracy\",cv=10)[\"test_score\"])\n",
    "#     results.append(np.append(np.array(pipe.steps)[:,0],res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length            float64\n",
       "diameter          float64\n",
       "height            float64\n",
       "whole_weight      float64\n",
       "shucked_weight    float64\n",
       "viscera_weight    float64\n",
       "shell_weight      float64\n",
       "type                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(results,columns=[\"Preprocessing\",\"Model\",\"Median-Accuracy\"]).sort_values(by=\"Median-Accuracy\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegamos o melhor modelo e preprocessamento, para testar no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline para o grid search\n",
    "pipe = make_pipeline(MinMaxScaler(feature_range=(0.1,1.0)),MLPClassifier())\n",
    "# Dicionario de parametros a serem testados pelo grid search\n",
    "logparameters = {'logisticregression__penalty':['l2'], 'logisticregression__solver':('newton-cg', 'lbfgs', 'sag', 'saga'), 'logisticregression__C': (np.arange(10,100,10)), 'logisticregression__multi_class':['multinomial'], 'logisticregression__max_iter':[1000]}\n",
    "mlpparameters = {'mlpclassifier__activation':['tanh'], 'mlpclassifier__solver': ['lbfgs'], 'mlpclassifier__max_iter': [100], 'mlpclassifier__alpha': [0.3], 'mlpclassifier__hidden_layer_sizes':[(16,8)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch com cros validation, testa o modelo com todas as combinações de parametros passadas no dicionario,\n",
    "# e classifica a melhor de acordo com uma metrica que escolhermos, nesse caso a acuracia.\n",
    "clf = GridSearchCV(pipe,mlpparameters,scoring=\"accuracy\", cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.41 s, sys: 1.49 s, total: 2.91 s\n",
      "Wall time: 10.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0.1, 1.0))), ('mlpclassifier', MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       lea...=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'mlpclassifier__activation': ['tanh'], 'mlpclassifier__solver': ['lbfgs'], 'mlpclassifier__max_iter': [100], 'mlpclassifier__alpha': [0.3], 'mlpclassifier__hidden_layer_sizes': [(16, 8)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(df.drop(columns=\"type\"),df[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de atributos recursivamente\n",
    "- selecionamos a melhor combinação de hiperparametros do modelo com o grid search\n",
    "- aplicamos a seleção de atributos nesse modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590038314176245"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0.1, 1.0))), ('mlpclassifier', MLPClassifier(activation='tanh', alpha=0.3, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(16, 8), learning_rate='constant',\n",
       "       learn...True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seletor = RFECV(log, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seletor.fit(df.drop(columns=\"type\"),df[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atributos selecionados\n",
    "#df.drop(columns=\"type\").columns[seletor.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.xlabel(\"Number of features selected\")\n",
    "# plt.ylabel(\"Cross validation score (accuracy)\")\n",
    "# plt.plot(range(1, len(seletor.grid_scores_) + 1), seletor.grid_scores_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando vetor resposta pra enviar ao servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mlp = MLPClassifier(activation='tanh', alpha=0.30000000000000004,hidden_layer_sizes=(16,), learning_rate='invscaling',learning_rate_init=0.1, max_iter=100, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bla = cross_validate(mlp,df.drop(columns=\"type\"),df[\"type\"],scoring=\"accuracy\",cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"abalone_dataset.csv\")\n",
    "# df.head()\n",
    "\n",
    "# df.dtypes\n",
    "\n",
    "# df = df.drop(columns=\"sex\")\n",
    "# type = df[\"type\"]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0.1,1.0))\n",
    "# dfscaled = scaler.fit_transform(df.drop(columns=\"type\"), df[\"type\"])\n",
    "# dfscaled = pd.DataFrame(dfscaled, columns=df.columns[:-1])\n",
    "\n",
    "# dfscaled = pd.merge(dfscaled,pd.DataFrame(type),right_index=True,left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.fit(dfscaled.drop(columns=\"type\"),dfscaled[\"type\"])\n",
    "teste = pd.read_csv(\"abalone_app.csv\")\n",
    "# teste['sex'] = LabelEncoder().fit_transform(teste['sex'].tolist())\n",
    "#teste['sex'] = teste['sex'].astype('category')\n",
    "teste = teste.drop(columns=\"sex\")\n",
    "testescaled = scaler.fit_transform(teste)\n",
    "testescaled = pd.DataFrame(testescaled,columns=teste.columns)\n",
    "pd.Series(clf.best_estimator_.predict(testescaled)).to_csv(\"respostas.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv(\"respostas.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [3],\n",
       "       ...,\n",
       "       [2],\n",
       "       [3],\n",
       "       [2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Lendo o arquivo com o dataset sobre abalone\n",
      " - Resposta do servidor:\n",
      " {\"error\":{\"code\":102,\"message\":\"Espere ao menos 12 horas entre dois envios, tempo restante 00 dias 00 horas 50 minutos 42 segundos\"}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "print('\\n - Lendo o arquivo com o dataset sobre abalone')\n",
    "\n",
    "# abalone = pd.read_csv('abalone_min_max.csv')\n",
    "\n",
    "# # Criando X and y par ao algorítmo de aprendizagem de máquina.\n",
    "# print(' - Criando X e y para o algoritmo de aprendizagem a partir do arquivo')\n",
    "# X,Y = abalone[abalone.columns[:-1]],abalone[abalone.columns[-1]]\n",
    "# Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, stratify = Y, random_state=66, test_size=0.10)\n",
    "\n",
    "# # Ciando o modelo preditivo para a base trabalhada\n",
    "# print(' - Criando modelo preditivo')\n",
    "# svm = SVC(kernel='rbf',gamma=5, C=100)\n",
    "# svm.fit(Xtrain,Ytrain)\n",
    "\n",
    "# #realizando previsões com o arquivo de\n",
    "# print(' - Aplicando modelo e enviando para o servidor')\n",
    "# abalone_app = pd.read_csv('abalone_app_min_max.csv')\n",
    "# y_pred = svm.predict(abalone_app)\n",
    "y_pred = pd.read_csv(\"respostas.csv\")\n",
    "\n",
    "# Enviando previsões realizadas com o modelo para o servidor\n",
    "URL = \"https://aydanomachado.com/mlclass/03_Validation.php\"\n",
    "\n",
    "#TODO Substituir pela sua chave aqui\n",
    "DEV_KEY = 'Ponte de Safena'\n",
    "\n",
    "# json para ser enviado para o servidor\n",
    "y_pred1 =pd.Series(np.array(y_pred).transpose()[0])\n",
    "data = {'dev_key':DEV_KEY,\n",
    "        'predictions':y_pred.to_json(orient='values')}\n",
    "\n",
    "# Enviando requisição e salvando o objeto resposta\n",
    "r = requests.post(url = URL, data = data)\n",
    "\n",
    "# Extraindo e imprimindo o texto da resposta\n",
    "pastebin_url = r.text\n",
    "print(\" - Resposta do servidor:\\n\", r.text, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[2,2,3,3,2,3,2,3,3,3,2,2,3,2,3,2,3,3,2,2,2,2,2,2,2,2,2,3,3,2,2,3,3,2,2,2,3,2,2,2,3,3,3,2,3,3,3,3,2,2,3,3,3,2,3,3,2,3,2,3,3,2,3,2,2,2,2,3,1,2,3,2,2,3,3,3,2,2,2,3,2,2,2,2,3,2,2,2,3,3,2,3,2,2,2,3,2,2,1,2,3,2,3,2,2,3,3,2,2,2,2,2,3,3,2,2,2,2,2,2,2,2,3,3,3,2,3,1,3,2,1,3,2,2,3,2,3,2,2,2,3,2,2,3,2,2,2,1,2,3,3,2,2,2,2,3,2,3,2,2,2,3,2,3,2,3,2,2,2,2,2,3,2,2,2,2,2,2,2,1,2,2,2,2,2,2,3,3,2,2,2,2,3,3,2,2,2,3,1,2,2,1,2,2,1,3,2,2,3,1,2,3,2,3,2,1,2,3,3,3,2,2,2,1,3,2,2,2,3,3,1,3,2,3,2,3,3,2,2,2,3,2,3,3,3,3,2,2,2,2,3,2,2,2,3,2,3,2,3,2,2,2,3,2,2,3,3,2,2,2,2,2,2,2,2,2,3,3,3,2,2,2,2,2,3,2,2,2,2,3,2,2,2,3,2,2,2,2,2,2,2,2,2,3,3,2,3,2,2,2,2,3,3,2,2,2,3,1,3,3,2,2,2,2,3,3,3,2,3,2,3,3,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,1,3,2,3,2,2,3,2,2,2,3,3,3,2,2,3,3,2,2,2,2,3,1,1,3,2,2,2,2,1,3,2,2,2,2,3,3,2,2,2,2,2,2,3,3,3,2,3,2,1,2,2,2,3,2,2,2,2,2,3,3,2,2,2,3,3,3,2,2,2,3,2,2,2,2,3,3,2,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,3,2,3,3,3,3,3,3,3,2,2,3,2,3,2,2,2,3,3,3,3,2,2,2,2,2,2,2,1,2,2,3,2,2,3,3,2,2,3,2,3,3,3,2,3,2,2,3,2,2,2,2,2,3,2,2,2,1,3,2,2,2,2,2,2,2,3,3,3,2,2,3,2,2,3,2,2,2,3,2,1,3,2,3,2,2,2,2,3,3,2,2,2,2,3,3,3,2,3,3,2,2,2,2,2,2,2,3,2,2,2,2,3,2,3,2,3,2,3,3,3,3,2,2,2,2,3,3,2,2,1,3,3,2,2,2,2,2,3,3,1,3,3,2,2,3,2,2,2,2,3,3,3,2,2,2,2,2,3,1,1,2,3,2,2,2,3,2,1,2,2,2,2,2,3,2,2,3,3,2,2,1,2,2,3,3,2,3,2,2,2,2,2,2,3,3,2,3,2,1,3,3,3,2,2,3,3,3,3,1,2,2,2,2,2,2,3,2,2,3,2,2,2,2,3,2,2,2,2,2,3,2,1,3,2,2,2,3,2,2,3,3,2,2,2,2,2,3,2,3,3,2,2,2,2,2,3,3,3,2,3,2,3,3,2,2,3,3,2,2,2,3,3,2,3,2,3,2,2,2,2,2,3,3,3,2,2,2,2,2,3,3,2,2,3,2,3,3,1,2,2,2,2,3,3,3,2,2,2,2,2,3,2,3,2,3,2,2,3,2,3,2,2,3,2,3,3,2,3,2,2,1,3,2,3,3,2,2,3,2,3,2,2,1,2,3,3,2,3,3,2,2,2,3,2,2,2,2,2,3,1,2,3,3,3,2,2,1,2,2,3,2,3,2,2,2,2,2,3,2,2,2,3,2,2,2,2,2,2,3,2,2,2,2,2,2,3,2,3,3,2,3,2,2,3,2,3,2,2,3,3,3,3,2,2,2,3,3,2,3,2,2,2,2,2,3,3,2,3,2,2,1,2,1,3,2,3,2,3,3,3,2,3,3,2,3,2,3,2,3,3,3,1,2,3,2,1,2,2,2,3,3,2,2,2,2,3,2,1,2,3,3,3,3,2,3,2,3,1,2,3,3,3,2,2,2,3,2,2,3,2,2,3,2,2,2,1,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,2,1,2,2,2,2,2,2,2,3,3,2,2,2,2,3,3,2,2,2,1,2,2,3,2,3,3,3,2,2,2,3,3,2,3,3,2,2,3,3,2,3,2,2,2,2,2,2,2,2,2,2,3,2,2,3,2,2,3,3,2,3,3,3,2,2,2,2,2,3,3,3,1,3,2,2,2,3,2,2,2,2,3,2]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1.to_json(orient='values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
