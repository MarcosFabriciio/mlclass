{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer,StandardScaler,MaxAbsScaler, LabelEncoder\n",
    "\n",
    "#import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Transformando a coluna de sexo de testo pra numero e considerando ela como dado categorico\n",
    "df = pd.read_csv(\"abalone_dataset.csv\")\n",
    "#df['sex'] = LabelEncoder().fit_transform(df['sex'].tolist())\n",
    "#df['sex'] = df['sex'].astype('category')\n",
    "df = df.drop(columns = \"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento da base\n",
    "preps = [MinMaxScaler,Normalizer,StandardScaler,MaxAbsScaler]\n",
    "# Modelos a serem testados\n",
    "models = [SVC,LogisticRegression,MLPClassifier,RandomForestClassifier,DecisionTreeClassifier]\n",
    "# Pipeline para testar todos os modelos com todos os preprocessamento\n",
    "pipes = [make_pipeline(prepo(),model()) for model in models for prepo in preps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/mfos/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for pipe in pipes:\n",
    "    res = np.median(cross_validate(pipe,df.drop(columns=\"type\"),df[\"type\"],scoring=\"accuracy\",cv=10)[\"test_score\"])\n",
    "    results.append(np.append(np.array(pipe.steps)[:,0],res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length            float64\n",
       "diameter          float64\n",
       "height            float64\n",
       "whole_weight      float64\n",
       "shucked_weight    float64\n",
       "viscera_weight    float64\n",
       "shell_weight      float64\n",
       "type                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Model</th>\n",
       "      <th>Median-Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.672500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.656047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.656007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.655496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.649122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.645932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.634185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.632588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.632177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.628799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.620802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.619199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.618816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.617224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.611821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.611202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.566875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.552721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.549521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.543131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Preprocessing                   Model  Median-Accuracy\n",
       "10  standardscaler           mlpclassifier         0.672500\n",
       "2   standardscaler                     svc         0.656047\n",
       "6   standardscaler      logisticregression         0.656007\n",
       "11    maxabsscaler           mlpclassifier         0.655496\n",
       "8     minmaxscaler           mlpclassifier         0.649122\n",
       "9       normalizer           mlpclassifier         0.645932\n",
       "4     minmaxscaler      logisticregression         0.634185\n",
       "7     maxabsscaler      logisticregression         0.632588\n",
       "5       normalizer      logisticregression         0.632177\n",
       "13      normalizer  randomforestclassifier         0.628799\n",
       "0     minmaxscaler                     svc         0.620802\n",
       "3     maxabsscaler                     svc         0.619199\n",
       "15    maxabsscaler  randomforestclassifier         0.618816\n",
       "14  standardscaler  randomforestclassifier         0.617224\n",
       "12    minmaxscaler  randomforestclassifier         0.611821\n",
       "1       normalizer                     svc         0.611202\n",
       "17      normalizer  decisiontreeclassifier         0.566875\n",
       "18  standardscaler  decisiontreeclassifier         0.552721\n",
       "16    minmaxscaler  decisiontreeclassifier         0.549521\n",
       "19    maxabsscaler  decisiontreeclassifier         0.543131"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results,columns=[\"Preprocessing\",\"Model\",\"Median-Accuracy\"]).sort_values(by=\"Median-Accuracy\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegamos o melhor modelo e preprocessamento, para testar no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline para o grid search\n",
    "pipe = make_pipeline(StandardScaler(),LogisticRegression())\n",
    "# Dicionario de parametros a serem testados pelo grid search\n",
    "parameters = {'logisticregression__penalty':['l2'], 'logisticregression__solver':('newton-cg', 'lbfgs', 'sag', 'saga'), 'logisticregression__C': (np.arange(10,100,10)), 'logisticregression__multi_class':['multinomial'], 'logisticregression__max_iter':[1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch com cros validation, testa o modelo com todas as combinações de parametros passadas no dicionario,\n",
    "# e classifica a melhor de acordo com uma metrica que escolhermos, nesse caso a acuracia.\n",
    "clf = GridSearchCV(pipe,parameters,scoring=\"accuracy\", cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 48.2 ms, total: 1.1 s\n",
      "Wall time: 9.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'logisticregression__penalty': ['l2'], 'logisticregression__solver': ('newton-cg', 'lbfgs', 'sag', 'saga'), 'logisticregression__C': array([10, 20, 30, 40, 50, 60, 70, 80, 90]), 'logisticregression__multi_class': ['multinomial'], 'logisticregression__max_iter': [1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(df.drop(columns=\"type\"),df[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de atributos recursivamente\n",
    "- selecionamos a melhor combinação de hiperparametros do modelo com o grid search\n",
    "- aplicamos a seleção de atributos nesse modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = clf.best_estimator_.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seletor = RFECV(log, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=10,\n",
       "   estimator=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "   min_features_to_select=1, n_jobs=None, scoring='accuracy', step=1,\n",
       "   verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seletor.fit(df.drop(columns=\"type\"),df[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['length', 'diameter', 'height', 'whole_weight', 'shucked_weight',\n",
       "       'viscera_weight', 'shell_weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Atributos selecionados\n",
    "df.drop(columns=\"type\").columns[seletor.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd17c05d780>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (accuracy)\")\n",
    "plt.plot(range(1, len(seletor.grid_scores_) + 1), seletor.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando vetor resposta pra enviar ao servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.read_csv(\"abalone_app.csv\")\n",
    "#teste['sex'] = LabelEncoder().fit_transform(teste['sex'].tolist())\n",
    "#teste['sex'] = teste['sex'].astype('category')\n",
    "teste = teste.drop(columns=\"sex\")\n",
    "base = teste[teste.columns[seletor.get_support()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.2290</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.4150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.1185</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.2445</td>\n",
       "      <td>0.2845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.3170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3715</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.5555</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.4440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.415</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.1545</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.235</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.2040</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>0.3225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.575</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.9215</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.1045</td>\n",
       "      <td>0.4565</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.695</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.6365</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>0.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.185</td>\n",
       "      <td>1.5280</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.3025</td>\n",
       "      <td>0.4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.505</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.3610</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.1155</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.3790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.745</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.9310</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.4585</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.605</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.3820</td>\n",
       "      <td>0.6090</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.555</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.2095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.570</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.635</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.3750</td>\n",
       "      <td>0.6230</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.3585</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.3745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.635</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.2615</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9740</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.4085</td>\n",
       "      <td>0.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.7510</td>\n",
       "      <td>0.8950</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.4700</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.4020</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.2935</td>\n",
       "      <td>0.3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.4385</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>0.2745</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.260</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.8045</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.6190</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.4650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.7825</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.4285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1.0485</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7995</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>0.515</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.6115</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3100</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.705</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.215</td>\n",
       "      <td>2.1410</td>\n",
       "      <td>1.0465</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0.665</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.2695</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.265</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.205</td>\n",
       "      <td>2.2635</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.4230</td>\n",
       "      <td>0.7260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0.510</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.3435</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0.615</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.1980</td>\n",
       "      <td>0.7070</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>0.2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.5075</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>0.430</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.0770</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.3095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "0      0.600     0.480   0.175        1.2290          0.4125          0.2735   \n",
       "1      0.545     0.385   0.150        1.1185          0.5425          0.2445   \n",
       "2      0.645     0.520   0.180        1.2850          0.5775          0.3520   \n",
       "3      0.640     0.510   0.170        1.3715          0.5670          0.3070   \n",
       "4      0.655     0.540   0.215        1.5555          0.6950          0.2960   \n",
       "5      0.415     0.300   0.100        0.3355          0.1545          0.0685   \n",
       "6      0.235     0.175   0.065        0.0615          0.0205          0.0200   \n",
       "7      0.655     0.490   0.160        1.2040          0.5455          0.2615   \n",
       "8      0.575     0.450   0.165        0.9215          0.3275          0.2250   \n",
       "9      0.550     0.425   0.155        0.9175          0.2775          0.2430   \n",
       "10     0.590     0.500   0.165        1.1045          0.4565          0.2425   \n",
       "11     0.695     0.550   0.160        1.6365          0.6940          0.3005   \n",
       "12     0.660     0.505   0.185        1.5280          0.6900          0.3025   \n",
       "13     0.490     0.385   0.140        0.5425          0.1980          0.1270   \n",
       "14     0.505     0.380   0.135        0.6855          0.3610          0.1565   \n",
       "15     0.610     0.475   0.160        1.1155          0.3835          0.2230   \n",
       "16     0.580     0.445   0.145        0.8880          0.4100          0.1815   \n",
       "17     0.300     0.230   0.095        0.1385          0.0560          0.0365   \n",
       "18     0.745     0.565   0.215        1.9310          0.8960          0.4585   \n",
       "19     0.605     0.475   0.175        1.3820          0.6090          0.2325   \n",
       "20     0.555     0.430   0.125        0.7005          0.3395          0.1355   \n",
       "21     0.545     0.440   0.120        0.8565          0.3475          0.1715   \n",
       "22     0.375     0.290   0.085        0.2385          0.1180          0.0450   \n",
       "23     0.570     0.470   0.140        0.8710          0.3850          0.2110   \n",
       "24     0.635     0.490   0.175        1.3750          0.6230          0.2705   \n",
       "25     0.550     0.445   0.125        0.6720          0.2880          0.1365   \n",
       "26     0.620     0.475   0.195        1.3585          0.5935          0.3365   \n",
       "27     0.635     0.490   0.170        1.2615          0.5385          0.2665   \n",
       "28     0.500     0.400   0.165        0.7105          0.2700          0.1455   \n",
       "29     0.740     0.600   0.195        1.9740          0.5980          0.4085   \n",
       "...      ...       ...     ...           ...             ...             ...   \n",
       "1015   0.700     0.565   0.180        1.7510          0.8950          0.3355   \n",
       "1016   0.710     0.555   0.170        1.4700          0.5375          0.3800   \n",
       "1017   0.655     0.525   0.180        1.4020          0.6240          0.2935   \n",
       "1018   0.450     0.340   0.105        0.4385          0.2100          0.0925   \n",
       "1019   0.525     0.420   0.160        0.7560          0.2745          0.1730   \n",
       "1020   0.260     0.200   0.065        0.0960          0.0440          0.0270   \n",
       "1021   0.535     0.400   0.150        0.8045          0.3345          0.2125   \n",
       "1022   0.670     0.540   0.195        1.6190          0.7400          0.3305   \n",
       "1023   0.680     0.540   0.195        1.7825          0.5565          0.3235   \n",
       "1024   0.550     0.435   0.160        0.9060          0.3420          0.2190   \n",
       "1025   0.610     0.425   0.155        1.0485          0.5070          0.1955   \n",
       "1026   0.525     0.425   0.145        0.7995          0.3345          0.2090   \n",
       "1027   0.470     0.385   0.130        0.5870          0.2640          0.1170   \n",
       "1028   0.435     0.330   0.125        0.4060          0.1685          0.1055   \n",
       "1029   0.515     0.385   0.125        0.6115          0.3175          0.1265   \n",
       "1030   0.700     0.575   0.170        1.3100          0.5095          0.3140   \n",
       "1031   0.705     0.555   0.215        2.1410          1.0465          0.3830   \n",
       "1032   0.665     0.515   0.200        1.2695          0.5115          0.2675   \n",
       "1033   0.265     0.195   0.060        0.0920          0.0345          0.0250   \n",
       "1034   0.750     0.615   0.205        2.2635          0.8210          0.4230   \n",
       "1035   0.510     0.380   0.135        0.6810          0.3435          0.1420   \n",
       "1036   0.615     0.450   0.150        1.1980          0.7070          0.2095   \n",
       "1037   0.645     0.525   0.160        1.5075          0.7455          0.2450   \n",
       "1038   0.380     0.270   0.095        0.2190          0.0835          0.0515   \n",
       "1039   0.455     0.375   0.125        0.5330          0.2330          0.1060   \n",
       "1040   0.430     0.350   0.105        0.3660          0.1705          0.0855   \n",
       "1041   0.475     0.360   0.125        0.4470          0.1695          0.0810   \n",
       "1042   0.500     0.405   0.150        0.5965          0.2530          0.1260   \n",
       "1043   0.380     0.275   0.095        0.2425          0.1060          0.0485   \n",
       "1044   0.590     0.475   0.165        1.0770          0.4545          0.2440   \n",
       "\n",
       "      shell_weight  \n",
       "0           0.4150  \n",
       "1           0.2845  \n",
       "2           0.3170  \n",
       "3           0.4090  \n",
       "4           0.4440  \n",
       "5           0.0950  \n",
       "6           0.0190  \n",
       "7           0.3225  \n",
       "8           0.2560  \n",
       "9           0.3350  \n",
       "10          0.3400  \n",
       "11          0.4400  \n",
       "12          0.4410  \n",
       "13          0.1750  \n",
       "14          0.1610  \n",
       "15          0.3790  \n",
       "16          0.2425  \n",
       "17          0.0370  \n",
       "18          0.5000  \n",
       "19          0.3985  \n",
       "20          0.2095  \n",
       "21          0.2400  \n",
       "22          0.0695  \n",
       "23          0.2315  \n",
       "24          0.3950  \n",
       "25          0.2100  \n",
       "26          0.3745  \n",
       "27          0.3800  \n",
       "28          0.2250  \n",
       "29          0.7100  \n",
       "...            ...  \n",
       "1015        0.4460  \n",
       "1016        0.4310  \n",
       "1017        0.3650  \n",
       "1018        0.1200  \n",
       "1019        0.2750  \n",
       "1020        0.0300  \n",
       "1021        0.2100  \n",
       "1022        0.4650  \n",
       "1023        0.4285  \n",
       "1024        0.2950  \n",
       "1025        0.2740  \n",
       "1026        0.2400  \n",
       "1027        0.1740  \n",
       "1028        0.0960  \n",
       "1029        0.1500  \n",
       "1030        0.4200  \n",
       "1031        0.5280  \n",
       "1032        0.4360  \n",
       "1033        0.0245  \n",
       "1034        0.7260  \n",
       "1035        0.1700  \n",
       "1036        0.2505  \n",
       "1037        0.4325  \n",
       "1038        0.0700  \n",
       "1039        0.1850  \n",
       "1040        0.1100  \n",
       "1041        0.1400  \n",
       "1042        0.1850  \n",
       "1043        0.2100  \n",
       "1044        0.3095  \n",
       "\n",
       "[1045 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(seletor.estimator_.predict(base)).to_csv(\"respostas.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
