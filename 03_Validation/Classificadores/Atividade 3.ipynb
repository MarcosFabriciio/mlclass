{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcosfabricio/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,Normalizer,StandardScaler,MaxAbsScaler, LabelEncoder\n",
    "\n",
    "#import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Transformando a coluna de sexo de testo pra numero e considerando ela como dado categorico\n",
    "df = pd.read_csv(\"abalone_dataset.csv\")\n",
    "#df['sex'] = LabelEncoder().fit_transform(df['sex'].tolist())\n",
    "#df['sex'] = df['sex'].astype('category')\n",
    "df = df.drop(columns = \"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento da base\n",
    "preps = [MinMaxScaler,Normalizer,StandardScaler,MaxAbsScaler]\n",
    "# Modelos a serem testados\n",
    "models = [SVC,LogisticRegression,MLPClassifier,RandomForestClassifier,DecisionTreeClassifier]\n",
    "# Pipeline para testar todos os modelos com todos os preprocessamento\n",
    "pipes = [make_pipeline(prepo(),model()) for model in models for prepo in preps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for pipe in pipes:\n",
    "    res = np.median(cross_validate(pipe,df.drop(columns=\"type\"),df[\"type\"],scoring=\"accuracy\",cv=10)[\"test_score\"])\n",
    "    results.append(np.append(np.array(pipe.steps)[:,0],res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length            float64\n",
       "diameter          float64\n",
       "height            float64\n",
       "whole_weight      float64\n",
       "shucked_weight    float64\n",
       "viscera_weight    float64\n",
       "shell_weight      float64\n",
       "type                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Model</th>\n",
       "      <th>Median-Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.660809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.656047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.656007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.646497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.645367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>mlpclassifier</td>\n",
       "      <td>0.642173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.635769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.634185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.632588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>logisticregression</td>\n",
       "      <td>0.632177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.623213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.620802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.619199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.615016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.611202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>randomforestclassifier</td>\n",
       "      <td>0.600645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>maxabsscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.559620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>standardscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.558399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.558389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>minmaxscaler</td>\n",
       "      <td>decisiontreeclassifier</td>\n",
       "      <td>0.545604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Preprocessing                   Model  Median-Accuracy\n",
       "10  standardscaler           mlpclassifier         0.660809\n",
       "2   standardscaler                     svc         0.656047\n",
       "6   standardscaler      logisticregression         0.656007\n",
       "8     minmaxscaler           mlpclassifier         0.646497\n",
       "9       normalizer           mlpclassifier         0.645367\n",
       "11    maxabsscaler           mlpclassifier         0.642173\n",
       "13      normalizer  randomforestclassifier         0.635769\n",
       "4     minmaxscaler      logisticregression         0.634185\n",
       "7     maxabsscaler      logisticregression         0.632588\n",
       "5       normalizer      logisticregression         0.632177\n",
       "14  standardscaler  randomforestclassifier         0.623213\n",
       "0     minmaxscaler                     svc         0.620802\n",
       "3     maxabsscaler                     svc         0.619199\n",
       "15    maxabsscaler  randomforestclassifier         0.615016\n",
       "1       normalizer                     svc         0.611202\n",
       "12    minmaxscaler  randomforestclassifier         0.600645\n",
       "19    maxabsscaler  decisiontreeclassifier         0.559620\n",
       "18  standardscaler  decisiontreeclassifier         0.558399\n",
       "17      normalizer  decisiontreeclassifier         0.558389\n",
       "16    minmaxscaler  decisiontreeclassifier         0.545604"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results,columns=[\"Preprocessing\",\"Model\",\"Median-Accuracy\"]).sort_values(by=\"Median-Accuracy\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegamos o melhor modelo e preprocessamento, para testar no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline para o grid search\n",
    "pipe = make_pipeline(StandardScaler(),LogisticRegression())\n",
    "# Dicionario de parametros a serem testados pelo grid search\n",
    "logparameters = {'logisticregression__penalty':['l2'], 'logisticregression__solver':('newton-cg', 'lbfgs', 'sag', 'saga'), 'logisticregression__C': (np.arange(10,100,10)), 'logisticregression__multi_class':['multinomial'], 'logisticregression__max_iter':[1000]}\n",
    "mlpparameters = {'mlpclassifier__activation':['identity','logistic','tanh','relu'], 'mlpclassifier__solver':('adam', 'lbfgs','sgd'), 'mlpclassifier__alpha':(np.arange(0.1,1,0.1)), 'mlpclassifier__learning_rate':('constant','invscaling','adaptive'), 'mlpclassifier__max_iter':(np.arange(100,1000,100))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch com cros validation, testa o modelo com todas as combinações de parametros passadas no dicionario,\n",
    "# e classifica a melhor de acordo com uma metrica que escolhermos, nesse caso a acuracia.\n",
    "clf = GridSearchCV(pipe,logparameters,scoring=\"accuracy\", cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 12.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#clf.fit(df.drop(columns=\"type\"),df[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de atributos recursivamente\n",
    "- selecionamos a melhor combinação de hiperparametros do modelo com o grid search\n",
    "- aplicamos a seleção de atributos nesse modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#log = clf.best_estimator_.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seletor = RFECV(log, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seletor.fit(df.drop(columns=\"type\"),df[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atributos selecionados\n",
    "#df.drop(columns=\"type\").columns[seletor.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.xlabel(\"Number of features selected\")\n",
    "# plt.ylabel(\"Cross validation score (accuracy)\")\n",
    "# plt.plot(range(1, len(seletor.grid_scores_) + 1), seletor.grid_scores_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando vetor resposta pra enviar ao servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(activation='tanh', alpha=0.30000000000000004,hidden_layer_sizes=(16,), learning_rate='invscaling',learning_rate_init=0.001, max_iter=100, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = cross_validate(mlp,df.drop(columns=\"type\"),df[\"type\"],scoring=\"accuracy\",cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcosfabricio/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.77127862, 0.82356572, 0.7920053 , 0.82797742, 0.81627989,\n",
       "        0.66173005, 0.6902442 , 0.76810503, 0.42508197, 0.43153501]),\n",
       " 'score_time': array([0.00817609, 0.00139642, 0.00130033, 0.01150179, 0.00128698,\n",
       "        0.00120401, 0.00122333, 0.00118756, 0.00121856, 0.00082231]),\n",
       " 'test_score': array([0.66666667, 0.64649682, 0.69745223, 0.66453674, 0.68690096,\n",
       "        0.65495208, 0.64217252, 0.61022364, 0.68589744, 0.68269231]),\n",
       " 'train_score': array([0.66205183, 0.6682044 , 0.65649397, 0.66690316, 0.66193686,\n",
       "        0.66796736, 0.66938631, 0.67577155, 0.65957447, 0.66276596])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.5155</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  length  diameter  height  whole_weight  shucked_weight  \\\n",
       "0    2   0.535     0.420   0.150        0.6995          0.2575   \n",
       "1    1   0.510     0.380   0.115        0.5155          0.2150   \n",
       "2    1   0.185     0.130   0.045        0.0290          0.0120   \n",
       "3    2   0.550     0.450   0.170        0.8100          0.3170   \n",
       "4    1   0.535     0.415   0.150        0.5765          0.3595   \n",
       "\n",
       "   viscera_weight  shell_weight  type  \n",
       "0          0.1530        0.2400     3  \n",
       "1          0.1135        0.1660     1  \n",
       "2          0.0075        0.0095     1  \n",
       "3          0.1570        0.2200     3  \n",
       "4          0.1350        0.2250     1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"abalone_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                 int64\n",
       "length            float64\n",
       "diameter          float64\n",
       "height            float64\n",
       "whole_weight      float64\n",
       "shucked_weight    float64\n",
       "viscera_weight    float64\n",
       "shell_weight      float64\n",
       "type                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"sex\")\n",
    "type = df[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0.1,0.9))\n",
    "dfscaled = scaler.fit_transform(df.drop(columns=\"type\"), df[\"type\"])\n",
    "dfscaled = pd.DataFrame(dfscaled, columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfscaled = pd.merge(dfscaled,pd.DataFrame(type),right_index=True,left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(dfscaled.drop(columns=\"type\"),dfscaled[\"type\"])\n",
    "teste = pd.read_csv(\"abalone_app.csv\")\n",
    "#teste['sex'] = LabelEncoder().fit_transform(teste['sex'].tolist())\n",
    "#teste['sex'] = teste['sex'].astype('category')\n",
    "teste = teste.drop(columns=\"sex\")\n",
    "testescaled = scaler.fit_transform(teste)\n",
    "testescaled = pd.DataFrame(testescaled,columns=teste.columns)\n",
    "pd.Series(mlp.predict(testescaled)).to_csv(\"respostas.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.582586</td>\n",
       "      <td>0.571752</td>\n",
       "      <td>0.314778</td>\n",
       "      <td>0.331411</td>\n",
       "      <td>0.290665</td>\n",
       "      <td>0.287333</td>\n",
       "      <td>0.286640</td>\n",
       "      <td>1.991379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.130547</td>\n",
       "      <td>0.133915</td>\n",
       "      <td>0.060903</td>\n",
       "      <td>0.138710</td>\n",
       "      <td>0.119152</td>\n",
       "      <td>0.115395</td>\n",
       "      <td>0.110983</td>\n",
       "      <td>0.824561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.505405</td>\n",
       "      <td>0.489916</td>\n",
       "      <td>0.270874</td>\n",
       "      <td>0.223074</td>\n",
       "      <td>0.197108</td>\n",
       "      <td>0.195194</td>\n",
       "      <td>0.200448</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.602703</td>\n",
       "      <td>0.590756</td>\n",
       "      <td>0.317476</td>\n",
       "      <td>0.322419</td>\n",
       "      <td>0.277270</td>\n",
       "      <td>0.276432</td>\n",
       "      <td>0.278176</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.678378</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.356311</td>\n",
       "      <td>0.422897</td>\n",
       "      <td>0.367115</td>\n",
       "      <td>0.362936</td>\n",
       "      <td>0.356801</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length     diameter       height  whole_weight  shucked_weight  \\\n",
       "count  3132.000000  3132.000000  3132.000000   3132.000000     3132.000000   \n",
       "mean      0.582586     0.571752     0.314778      0.331411        0.290665   \n",
       "std       0.130547     0.133915     0.060903      0.138710        0.119152   \n",
       "min       0.100000     0.100000     0.100000      0.100000        0.100000   \n",
       "25%       0.505405     0.489916     0.270874      0.223074        0.197108   \n",
       "50%       0.602703     0.590756     0.317476      0.322419        0.277270   \n",
       "75%       0.678378     0.671429     0.356311      0.422897        0.367115   \n",
       "max       0.900000     0.900000     0.900000      0.900000        0.900000   \n",
       "\n",
       "       viscera_weight  shell_weight         type  \n",
       "count     3132.000000   3132.000000  3132.000000  \n",
       "mean         0.287333      0.286640     1.991379  \n",
       "std          0.115395      0.110983     0.824561  \n",
       "min          0.100000      0.100000     1.000000  \n",
       "25%          0.195194      0.200448     1.000000  \n",
       "50%          0.276432      0.278176     2.000000  \n",
       "75%          0.362936      0.356801     3.000000  \n",
       "max          0.900000      0.900000     3.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfscaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.591616</td>\n",
       "      <td>0.575028</td>\n",
       "      <td>0.188845</td>\n",
       "      <td>0.365109</td>\n",
       "      <td>0.354826</td>\n",
       "      <td>0.368113</td>\n",
       "      <td>0.321333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.155763</td>\n",
       "      <td>0.158308</td>\n",
       "      <td>0.035081</td>\n",
       "      <td>0.155107</td>\n",
       "      <td>0.156292</td>\n",
       "      <td>0.160694</td>\n",
       "      <td>0.126171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.496694</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.172072</td>\n",
       "      <td>0.240954</td>\n",
       "      <td>0.230998</td>\n",
       "      <td>0.241522</td>\n",
       "      <td>0.219545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.615702</td>\n",
       "      <td>0.601010</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.337478</td>\n",
       "      <td>0.355179</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.708264</td>\n",
       "      <td>0.689899</td>\n",
       "      <td>0.208108</td>\n",
       "      <td>0.467521</td>\n",
       "      <td>0.458319</td>\n",
       "      <td>0.475435</td>\n",
       "      <td>0.407273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length     diameter       height  whole_weight  shucked_weight  \\\n",
       "count  1045.000000  1045.000000  1045.000000   1045.000000     1045.000000   \n",
       "mean      0.591616     0.575028     0.188845      0.365109        0.354826   \n",
       "std       0.155763     0.158308     0.035081      0.155107        0.156292   \n",
       "min       0.100000     0.100000     0.100000      0.100000        0.100000   \n",
       "25%       0.496694     0.479798     0.172072      0.240954        0.230998   \n",
       "50%       0.615702     0.601010     0.190090      0.355893        0.337478   \n",
       "75%       0.708264     0.689899     0.208108      0.467521        0.458319   \n",
       "max       0.900000     0.900000     0.900000      0.900000        0.900000   \n",
       "\n",
       "       viscera_weight  shell_weight  \n",
       "count     1045.000000   1045.000000  \n",
       "mean         0.368113      0.321333  \n",
       "std          0.160694      0.126171  \n",
       "min          0.100000      0.100000  \n",
       "25%          0.241522      0.219545  \n",
       "50%          0.355179      0.318182  \n",
       "75%          0.475435      0.407273  \n",
       "max          0.900000      0.900000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testescaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv(\"respostas.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [2],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Lendo o arquivo com o dataset sobre abalone\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "print('\\n - Lendo o arquivo com o dataset sobre abalone')\n",
    "\n",
    "# abalone = pd.read_csv('abalone_min_max.csv')\n",
    "\n",
    "# # Criando X and y par ao algorítmo de aprendizagem de máquina.\n",
    "# print(' - Criando X e y para o algoritmo de aprendizagem a partir do arquivo')\n",
    "# X,Y = abalone[abalone.columns[:-1]],abalone[abalone.columns[-1]]\n",
    "# Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, stratify = Y, random_state=66, test_size=0.10)\n",
    "\n",
    "# # Ciando o modelo preditivo para a base trabalhada\n",
    "# print(' - Criando modelo preditivo')\n",
    "# svm = SVC(kernel='rbf',gamma=5, C=100)\n",
    "# svm.fit(Xtrain,Ytrain)\n",
    "\n",
    "# #realizando previsões com o arquivo de\n",
    "# print(' - Aplicando modelo e enviando para o servidor')\n",
    "# abalone_app = pd.read_csv('abalone_app_min_max.csv')\n",
    "# y_pred = svm.predict(abalone_app)\n",
    "y_pred = pd.read_csv(\"respostas.csv\")\n",
    "\n",
    "# Enviando previsões realizadas com o modelo para o servidor\n",
    "URL = \"https://aydanomachado.com/mlclass/03_Validation.php\"\n",
    "\n",
    "#TODO Substituir pela sua chave aqui\n",
    "DEV_KEY = 'Ponte de Safena'\n",
    "\n",
    "# json para ser enviado para o servidor\n",
    "y_pred1 =pd.Series(np.array(y_pred).transpose()[0])\n",
    "data = {'dev_key':DEV_KEY,\n",
    "        'predictions':y_pred.to_json(orient='values')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       1\n",
       "5       1\n",
       "6       2\n",
       "7       2\n",
       "8       3\n",
       "9       2\n",
       "10      2\n",
       "11      2\n",
       "12      1\n",
       "13      1\n",
       "14      3\n",
       "15      1\n",
       "16      1\n",
       "17      2\n",
       "18      2\n",
       "19      1\n",
       "20      1\n",
       "21      1\n",
       "22      1\n",
       "23      2\n",
       "24      1\n",
       "25      2\n",
       "26      2\n",
       "27      1\n",
       "28      3\n",
       "29      2\n",
       "       ..\n",
       "1014    2\n",
       "1015    3\n",
       "1016    2\n",
       "1017    1\n",
       "1018    3\n",
       "1019    1\n",
       "1020    1\n",
       "1021    2\n",
       "1022    3\n",
       "1023    2\n",
       "1024    1\n",
       "1025    1\n",
       "1026    1\n",
       "1027    1\n",
       "1028    1\n",
       "1029    2\n",
       "1030    2\n",
       "1031    2\n",
       "1032    1\n",
       "1033    3\n",
       "1034    1\n",
       "1035    1\n",
       "1036    2\n",
       "1037    1\n",
       "1038    1\n",
       "1039    1\n",
       "1040    1\n",
       "1041    1\n",
       "1042    1\n",
       "1043    2\n",
       "Length: 1044, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1,2,2,2,1,1,2,2,3,2,2,2,1,1,3,1,1,2,2,1,1,1,1,2,1,2,2,1,3,2,1,1,3,1,1,1,3,2,1,1,1,3,1,2,3,3,3,2,1,1,3,3,3,2,3,2,1,1,1,2,3,2,2,1,1,2,2,2,1,1,3,1,1,1,1,1,1,1,1,2,1,1,2,1,2,1,1,1,1,1,1,3,1,2,1,2,2,1,1,2,1,1,2,2,1,1,3,2,2,1,2,1,2,1,2,1,1,1,1,1,1,2,3,1,2,1,1,1,2,2,1,2,1,1,1,2,2,1,1,1,3,1,1,1,1,1,1,1,1,3,1,1,1,1,2,2,1,1,1,1,2,3,1,3,1,3,2,1,1,2,1,1,2,2,2,2,1,1,1,1,1,2,1,1,2,1,3,1,2,2,2,1,3,3,1,1,2,3,1,1,1,1,1,1,1,1,1,2,2,1,1,2,1,3,2,1,1,2,1,3,1,1,1,1,2,1,2,1,2,1,1,2,1,1,1,2,1,1,1,2,3,1,3,1,1,3,2,1,1,1,3,2,1,1,2,1,3,2,1,2,1,2,2,1,2,2,3,1,1,2,1,1,2,1,1,1,2,1,1,2,1,1,1,1,2,2,1,2,1,2,1,1,1,2,2,1,1,1,2,1,1,1,1,3,2,1,2,2,2,1,2,1,3,1,2,2,1,1,2,2,1,1,1,2,2,1,1,1,3,1,3,1,1,2,1,1,1,1,1,1,2,2,1,1,2,1,1,1,1,1,3,1,2,2,2,2,2,1,2,3,1,2,1,2,1,1,2,2,3,1,1,3,1,2,2,1,1,1,1,1,2,1,2,3,1,1,1,1,1,1,1,1,3,1,1,1,1,1,1,1,1,2,2,1,2,1,3,1,2,1,1,2,1,3,1,2,2,1,1,1,2,1,3,3,1,2,1,1,2,2,1,1,1,1,1,1,1,2,1,2,1,2,1,1,2,1,1,1,1,2,1,2,3,2,1,1,1,1,1,1,2,2,1,2,2,1,2,2,2,1,1,2,2,1,1,2,1,2,1,2,2,1,1,1,1,1,1,2,3,1,3,1,2,3,2,2,1,2,2,1,1,2,2,1,1,1,2,2,1,1,2,1,1,1,2,1,2,2,2,2,3,1,1,1,3,2,1,1,1,3,1,1,1,1,1,2,1,1,1,1,3,3,3,1,2,1,1,1,1,1,2,2,1,2,1,2,2,2,1,1,3,1,2,1,1,2,2,2,2,1,1,1,2,2,1,2,1,1,2,2,1,1,1,1,3,2,1,1,1,2,1,3,1,1,2,1,3,1,1,3,1,1,1,1,2,1,1,2,1,1,2,1,3,1,1,1,2,1,1,1,1,2,1,3,2,1,1,1,2,2,1,1,2,3,2,1,1,1,1,1,1,3,2,3,1,1,1,3,1,1,2,2,1,2,1,1,1,2,1,1,1,2,1,1,1,2,1,1,1,1,1,1,1,1,2,1,3,1,1,1,2,1,1,2,2,1,3,3,1,1,2,1,1,1,2,2,3,2,1,1,1,1,3,3,1,1,2,2,3,1,1,1,1,2,1,1,1,2,2,1,2,2,1,2,1,1,1,1,1,2,1,1,1,1,2,1,3,1,1,1,3,1,1,2,1,1,1,1,2,3,1,2,1,2,2,2,1,1,1,1,1,3,2,1,3,1,2,2,2,1,1,3,1,1,3,2,2,1,1,1,1,1,1,1,2,1,3,2,1,1,1,3,1,1,1,2,2,1,1,3,2,2,1,2,1,2,1,2,2,2,3,1,1,1,1,2,3,1,1,1,1,2,2,1,1,2,1,2,1,1,2,1,1,1,1,1,1,2,1,1,2,1,2,2,3,1,2,2,1,2,1,2,1,2,1,2,1,1,3,2,1,1,1,2,1,1,2,1,1,2,1,3,3,1,3,1,1,1,1,1,1,1,3,1,3,3,2,1,3,2,2,3,2,3,2,2,2,1,1,1,2,1,1,1,2,2,1,1,2,2,1,1,2,1,1,1,2,2,3,1,2,3,1,3,1,2,3,1,3,2,1,1,2,1,1,2,1,1,1,1,2,1,1,1,2,2,1,1,2,1,3,1,1,1,2,1,1,1,1,1,2,1,1,1,2,2,2,1,1,1,1,1,2,1,1,3,2,2,1,2,1,1,1,3,1,3,3,1,1,1,2,3,2,1,1,1,2,2,3,2,1,2,2,2,2,2,1,1,2,1,2,1,1,2,2,3,2,1,3,1,1,2,3,2,1,1,1,1,1,2,2,2,1,3,1,1,2,1,1,1,1,1,1,2]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1.to_json(orient='values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
